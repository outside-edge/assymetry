{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9915217",
   "metadata": {},
   "source": [
    "To obtain match-level data, I first scraped search results from ESPNCricinfo using Python libraries `requests` and `BeautifulSoup`. The resulting JSON files were organized by match type and contained the ESPNCricinfo unique match id numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup, UnicodeDammit\n",
    "\n",
    "for match_type in ['list', 'first', 'odi', 'test', 't20i', 't20']:\n",
    "    results = []\n",
    "    r = requests.get('http://search.espncricinfo.com/ci/content/match/search.html?all=1;page=0;search=' + match_type)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    last_match = int(soup.find_all('span', attrs={'class':'PaginationNmbrs'})[-1].text)\n",
    "    last_page = int(math.ceil(float(last_match)/float(20)))\n",
    "    for i in range(0, last_page):\n",
    "        time.sleep(1)\n",
    "        results_page = requests.get(\"http://search.espncricinfo.com/ci/content/match/search.html?search={0};all=1;page={1}\".format(match_type, i))\n",
    "        soupy = BeautifulSoup(results_page.text, \"html.parser\")\n",
    "        for new_host in soupy.find_all('a', {'class' : 'srchPlyrNmTxt'}):\n",
    "            try:\n",
    "                new_host = UnicodeDammit(new_host['href']).unicode_markup\n",
    "            except:\n",
    "                continue\n",
    "            print(new_host.split(\"/\")[4].split('.')[0])\n",
    "            results.append(new_host.split(\"/\")[4].split('.')[0])\n",
    "\n",
    "    if match_type == 'list':\n",
    "        file_name = 'list-a'\n",
    "    elif match_type == 'first':\n",
    "        file_name = 'first-class'\n",
    "    else:\n",
    "        file_name = match_type\n",
    "\n",
    "    with open(\"matches-{0}.json\".format(file_name), \"w\") as f:\n",
    "        json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d7a01",
   "metadata": {},
   "source": [
    "Next, I combined the match-type specific files into a single JSON file. I used a purpose-built Python library (https://github.com/dwillis/python-espncricinfo) to retrieve data on the matches. The script ensured that a match ID was only retrieved once. If a match was not yet completed, did not have any JSON data or was missing a scorecard it was excluded from the results, formatted as a comma-separated values file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import json\n",
    "from espncricinfo.match import Match\n",
    "from espncricinfo.exceptions import MatchNotFoundError, NoScorecardError\n",
    "\n",
    "headers = [\"team1\", \"team1_id\", \"team2\", \"team2_id\", \"win_toss\", \"bat_or_bowl\", \"outcome\", \"win_game\", \"date\", \"day_n_night\", \"ground\", \"rain\", \"duckworth_lewis\", \"match_id\", \"type_of_match\", \"match_type_id\", \"home_team_id\", \"umpire_1_id\", \"umpire_1_name\", \"umpire_1_country\", \"umpire_2_id\", \"umpire_2_name\", \"umpire_2_country\", \"tv_umpire_id\", \"tv_umpire_name\", \"tv_umpire_country\", \"referree_id\", \"referee_name\", \"referee_country\", \"url\"]\n",
    "\n",
    "matches = json.loads(open('all_matches.json').read())\n",
    "matches = list(set(matches)) # dedupe\n",
    "\n",
    "bad_matches = []\n",
    "\n",
    "##################################START PROCESSING DATA#########################################\n",
    "\n",
    "with open(\"final_output.csv\", \"r\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(headers)\n",
    "    for match in matches:\n",
    "        if match in already_loaded:\n",
    "            continue\n",
    "        print(match)\n",
    "        time.sleep(0.5)\n",
    "        try:\n",
    "            m = Match(int(match))\n",
    "            if m.match_json()['match_status'] == 'forthcoming':\n",
    "                continue\n",
    "            if m.result == '':\n",
    "                continue\n",
    "            if m.rain_rule == 'D/L method':\n",
    "                duckworth_lewis = 1\n",
    "            else:\n",
    "                duckworth_lewis = 0\n",
    "            try:\n",
    "                m.team_2['team_name']\n",
    "            except KeyError:\n",
    "                continue\n",
    "            if m.match_class == '':\n",
    "                if 'T20' in m.comms_json['props']['pageProps']['data']['content']['about']['series']['text']:\n",
    "                    type_of_match = 'T20'\n",
    "                elif 'ODI' in m.comms_json['props']['pageProps']['data']['content']['about']['series']['text']:\n",
    "                    type_of_match = 'ODI'\n",
    "                else:\n",
    "                    type_of_match = None\n",
    "            else:\n",
    "                type_of_match = m.match_class\n",
    "            try:\n",
    "                m.team_1['team_name']\n",
    "            except KeyError:\n",
    "                continue\n",
    "            if m.match_json()['international_class_card'] != \"\":\n",
    "                match_type_id = m.match_json()['international_class_id']\n",
    "            else:\n",
    "                match_type_id = m.match_json()['general_class_id']\n",
    "            try:\n",
    "                if len(m.officials) > 0:\n",
    "                    umpires = [o for o in m.officials if o['player_type_name'] == 'umpire']\n",
    "                    tv_ump = [o for o in m.officials if o['player_type_name'] == 'tv umpire']\n",
    "                    match_ref = [o for o in m.officials if o['player_type_name'] == 'referee']\n",
    "                    if len(umpires) == 2:\n",
    "                        ump_1 = umpires[0]\n",
    "                        ump_2 = umpires[1]\n",
    "                    elif len(umpires) == 0:\n",
    "                        ump_1 = {'object_id': None, 'known_as': None, 'team_name': None}\n",
    "                        ump_2 = {'object_id': None, 'known_as': None, 'team_name': None}\n",
    "                    else:\n",
    "                        ump_1 = umpires[0]\n",
    "                        ump_2 = {'object_id': None, 'known_as': None, 'team_name': None}\n",
    "                else:\n",
    "                    ump_1 = {'object_id': None, 'known_as': None, 'team_name': None}\n",
    "                    ump_2 = {'object_id': None, 'known_as': None, 'team_name': None}\n",
    "            except ValueError:\n",
    "                raise\n",
    "            if len(tv_ump) > 0:\n",
    "                tvu_id = tv_ump[0]['object_id']\n",
    "                tvu_name = tv_ump[0]['known_as']\n",
    "                tvu_country = tv_ump[0]['team_name']\n",
    "            else:\n",
    "                tvu_id = None\n",
    "                tvu_name = None\n",
    "                tvu_country = None\n",
    "            if len(match_ref) > 0:\n",
    "                mr_id = match_ref[0]['object_id']\n",
    "                mr_name = match_ref[0]['known_as']\n",
    "                mr_country = match_ref[0]['team_name']\n",
    "            else:\n",
    "                mr_id = None\n",
    "                mr_name = None\n",
    "                mr_country = None\n",
    "            writer.writerow([m.team_1['team_name'], m.team_1_id, m.team_2['team_name'], m.team_2_id, m.toss_winner_team_id, m.toss_decision, m.result, m.match_json()['winner_team_id'], m.date, m.lighting, m.ground_name, None, duckworth_lewis, match, type_of_match, match_type_id, m.match_json()['home_team_id'], ump_1['object_id'], ump_1['known_as'], ump_1['team_name'], ump_2['object_id'], ump_2['known_as'], ump_2['team_name'], tvu_id, tvu_name, tvu_country, mr_id, mr_name, mr_country, m.match_url])\n",
    "        except (json.JSONDecodeError, NoScorecardError, MatchNotFoundError, KeyError):\n",
    "            bad_matches.append(match)\n",
    "            continue\n",
    "\n",
    "##################################FINISHED#########################################\n",
    "print(\"The following matches could not be parsed: \")\n",
    "print(bad_matches)\n",
    "print(\"DONE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043ccbe",
   "metadata": {},
   "source": [
    "Similarly, for ICC team rankings I used a Python scraper to obtain monthly rankings from archived pages on the ICC site. More recent rankings were obtained from a JSON API published by the ICC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ccfb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "\n",
    "MONTH_MAPPING = {\n",
    "    'JANUARY': 1,\n",
    "    'FEBRUARY': 2,\n",
    "    'MARCH': 3,\n",
    "    'APRIL': 4,\n",
    "    'MAY': 5,\n",
    "    'JUNE': 6,\n",
    "    'JULY': 7,\n",
    "    'AUGUST': 8,\n",
    "    'SEPTEMBER': 9,\n",
    "    'OCTOBER': 10,\n",
    "    'NOVEMBER': 11,\n",
    "    'DECEMBER': 12\n",
    "}\n",
    "\n",
    "FORMAT_RANGES = {\n",
    "    'test': range(1952, 2014),\n",
    "    'odi': range(1981, 2014)\n",
    "}\n",
    "\n",
    "def parser(format):\n",
    "    with open(\"../data/rankings_%s.csv\" % format, \"wb\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['format', 'year', 'month', 'rank', 'country', 'rating'])\n",
    "        for year in FORMAT_RANGES[format]:\n",
    "            rankings = fetch_rankings(year, format)\n",
    "            for ranking in rankings:\n",
    "                writer.writerow(ranking)\n",
    "\n",
    "def fetch_rankings(year, format):\n",
    "    results = []\n",
    "    url = \"http://web.archive.org/web/20130320093711/http://www.icc-cricket.com/match_zone/%s_ranking.php?year=%s\" % (format, year)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    month_links = soup.findAll('a', attrs={'style':'color:#666666;'})\n",
    "    months = [MONTH_MAPPING[m.text] for m in month_links]\n",
    "    tables = soup.findAll('table', attrs={'class':'dataBox topMargin'})\n",
    "    combo = zip(months, tables)\n",
    "    for month, table in combo:\n",
    "        for row in table.findAll('tr')[1:-1]:\n",
    "            rank, country, rating = [td.text for td in row.findAll('td')]\n",
    "            results.append([format, year, month, int(rank), country, int(rating)])\n",
    "    return results\n",
    "\n",
    "def fetch_current_rankings(format):\n",
    "    \"\"\"\n",
    "    format is one of: 'test', 'odi' or 't20i'\n",
    "    \"\"\"\n",
    "    r = requests.get(\"http://www.icc-cricket.com/api/getRankings\")\n",
    "    rankings_json = r.json()\n",
    "    return [r['rankings'] for r in rankings_json if r['matchType'] == format.upper()][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
